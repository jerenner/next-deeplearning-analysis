{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D projections for DNN-based reconstruction\n",
    "\n",
    "Our DNN-based strategy for reconstruction can be described as follows:\n",
    "\n",
    "Training:\n",
    "1. Run many events in a box of pure xenon. \n",
    "2. Place the event in a random location in the active region and drift all hits to the EL plane (applying both transverse and longitudinal diffusion). Voxelize with some small resolution and store the resulting (x,y,z) coordinates and energies in an HDF5 file.\n",
    "3. Slice the event in z, that is, make an x-y projection with some chosen pixel size (which may be larger than the x-y dimensions of the chosen voxel size in step 2).\n",
    "4. Determine the range of all slices (the maximum extent in x and y) and eliminate slices that have a range greater than some chosen value. It is assumed that in the analysis, slices with a range greater than this value will be broken up into smaller slices that fit within the chosen range. Collect all slices that fit within the chosen range to be used as training/validation/test events.\n",
    "5. For the collected slices, construct a corresponding SiPM map with a size large enough to fit the chosen range.\n",
    "6. Train a DNN to reconstruct slice projections from SiPM maps; (x = [the SiPM map], y = [corresponding projection])\n",
    "\n",
    "Analysis:\n",
    "1. We begin with slices created from real data (or data-like MC). In this case we only have access to the SiPM maps and not \n",
    "2. Find active regions along the SiPM plane and extract subsets corresponding to our slice region.\n",
    "3. Reconstruct the slice using the DNN.\n",
    "4. Piece the track together from the reconstructed slices. The reconstructed slice coordinates will need to be translated into real (x,y) coordinates by considering where in the tracking plane the SiPM subset was taken and the voxel sizes.\n",
    "\n",
    "* Note we may have to deal with \"clashes\" in slices, that is, two slices which together extend beyond the chosen DNN reconstruction range but are not separated enough to be covered by two completely independent reconstruction ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "# Sg_vs_Bg_dnn will use magbox SiPM response data to classify tracks into signal or background classes\n",
    "from   __future__         import print_function\n",
    "from   keras.optimizers   import SGD, Nadam\n",
    "from   keras.models       import Sequential, Model\n",
    "from   keras.layers       import Input, Dense, Activation, Conv2D, AveragePooling2D, MaxPooling2D, merge, Reshape, Flatten, Dropout\n",
    "from   keras              import callbacks\n",
    "from   matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import tables            as tb\n",
    "import numpy             as np\n",
    "import copy\n",
    "import h5py\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the 3D grid extent and range limits. Note that we have two potentially different voxel sizes: those in which the Geant4 events were originally voxelized (\"Geant4 voxels\") and those we are using for x-y projections (\"projection voxels\" - defined below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of events to read.\n",
    "nevtsTrain = 38000\n",
    "nevtsTest = 2000\n",
    "\n",
    "# SiPM plane geometry definition\n",
    "nsipm = 10             # number of SiPMs in response map (a 10x10 response map covers a 100x100 range)\n",
    "sipm_pitch = 10.       # distance between SiPMs\n",
    "sipm_edge_width = 5.   # distance between SiPM and edge of board\n",
    "\n",
    "# Range limit in x and y for slices (assuming a square range), in voxels\n",
    "RNG_LIM = 100\n",
    "\n",
    "gridSize = int(RNG_LIM*RNG_LIM)\n",
    "mapSize = nsipm*nsipm\n",
    "\n",
    "# Range limits from extraction of Geant4-simulated events.\n",
    "NX = 200\n",
    "NY = 200\n",
    "NZ = 200\n",
    "\n",
    "# Projection voxel sizes in mm\n",
    "vSizeX = 1\n",
    "vSizeY = 1\n",
    "\n",
    "# The slice width, in Geant4 voxels\n",
    "slice_width = 5.\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "# Variables for computing an EL point location\n",
    "xlen = 2*sipm_edge_width + (nsipm-1)*sipm_pitch       # (mm) side length of rectangle\n",
    "ylen = 2*sipm_edge_width + (nsipm-1)*sipm_pitch       # (mm) side length of rectangle\n",
    "wbin = 2.0                                            # (mm) bin width\n",
    "# Compute the positions of the SiPMs\n",
    "pos_x = np.ones(nsipm**2)*sipm_edge_width + (np.ones(nsipm*nsipm)*range(nsipm**2) % nsipm)*sipm_pitch\n",
    "pos_y = np.ones(nsipm**2)*sipm_edge_width + np.floor(np.ones(nsipm*nsipm)*range(nsipm**2) / nsipm)*sipm_pitch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct a DNN.\n",
    "def model_2dconv():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Reshape((1, nsipm, nsipm), input_shape=(nsipm*nsipm,)))\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', data_format=None))\n",
    "    model.add(Conv2D(256, (2, 2), padding='same', activation='relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(5, 5), strides=(5, 5), padding='same', data_format=None))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=RNG_LIM**2, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Nadam(\n",
    "        lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN training and reconstruction\n",
    "\n",
    "The stored events and SiPM maps can now be read in and used to train a DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(file_name,nevts_train,nevts_test,map_size,grid_size):\n",
    "\n",
    "    # Open the HDF5 file.\n",
    "    evt_file = h5py.File(file_name,'r')\n",
    "    tot_evts = int(len(evt_file)/3)\n",
    "    \n",
    "    # Make sure we have specified valid event numbers.\n",
    "    if(nevts_train+nevts_test > tot_evts):\n",
    "        print(\"ERROR: too many events specified\")\n",
    "        return None\n",
    "    \n",
    "    # Make sure we start reading test events on a boundary.\n",
    "    enum_last = evt_file[\"evtNum{0}\".format(nevts_train-1)][0]\n",
    "    enum_end  = evt_file[\"evtNum{0}\".format(nevts_train)][0]\n",
    "    while(enum_last == enum_end):\n",
    "        nevts_train += 1\n",
    "        nevts_test  -= 1\n",
    "        enum_end  = evt_file[\"evtNum{0}\".format(nevts_train)][0]\n",
    "        \n",
    "    enum_last = evt_file[\"evtNum{0}\".format(nevts_train+nevts_test-1)][0]\n",
    "    enum_end  = evt_file[\"evtNum{0}\".format(nevts_train+nevts_test)][0]\n",
    "    while(enum_last == enum_end and (nevts_train+nevts_test) < tot_evts):\n",
    "        nevts_test  += 1\n",
    "        enum_end  = evt_file[\"evtNum{0}\".format(nevts_train+nevts_test)][0]        \n",
    "    print(\"Reading {0} training events and {1} test events\".format(nevts_train,nevts_test))\n",
    "        \n",
    "    # Create the arrays to store the training and test events.\n",
    "    x_train = np.zeros([nevts_train,map_size])\n",
    "    x_test = np.zeros([nevts_test,map_size])\n",
    "    y_train = np.zeros([nevts_train,grid_size])\n",
    "    y_test = np.zeros([nevts_test,grid_size])\n",
    "    \n",
    "    # Start reading the events.\n",
    "    print(\"{0} events available\".format(tot_evts))\n",
    "    nevents = min(tot_evts,nevts_train+nevts_test)\n",
    "    for ee in range(nevents):\n",
    "\n",
    "        # Get the data from the HDF5 file.\n",
    "        slice_obj = evt_file[\"slice{0}\".format(ee)]\n",
    "        map_obj = evt_file[\"sipm{0}\".format(ee)]\n",
    "        evtnum_obj = evt_file[\"evtNum{0}\".format(ee)]\n",
    "\n",
    "        # Create the grid.\n",
    "        xslices = slice_obj[0]; yslices = slice_obj[1]; eslices = slice_obj[2]\n",
    "        slice_grid = np.zeros(gridSize)\n",
    "        for xv,yv,ev in zip(xslices,yslices,eslices):\n",
    "            igrid = int(xv + RNG_LIM*yv)\n",
    "            slice_grid[igrid] += ev\n",
    "\n",
    "        # Store the event.\n",
    "        if(ee >= nevts_train): \n",
    "            x_test[ee-nevts_train] = map_obj\n",
    "            y_test[ee-nevts_train] = slice_grid\n",
    "        else:\n",
    "            x_train[ee] = map_obj\n",
    "            y_train[ee] = slice_grid\n",
    "            \n",
    "    evt_file.close()\n",
    "    \n",
    "    return (x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data and train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = read_events(\"data/slices.h5\",nevtsTrain,nevtsTest,mapSize,gridSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot one event: grid distribution and corresponding SiPM map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one event.\n",
    "plt_train = True   # set to True to plot a training event, False to plot a test event\n",
    "pevt = 4            # the event number\n",
    "if(plt_train):\n",
    "    xarr = x_train[pevt]\n",
    "    yarr = y_train[pevt]\n",
    "else:\n",
    "    xarr = x_test[pevt]\n",
    "    yarr = y_test[pevt]\n",
    "\n",
    "# Create the figure.\n",
    "fig = plt.figure();\n",
    "fig.set_figheight(5.0)\n",
    "fig.set_figwidth(15.0)\n",
    "\n",
    "# Plot the SiPM response map.\n",
    "ax1 = fig.add_subplot(121); \n",
    "ax1.axis([0, xlen, 0, ylen]);\n",
    "probs = (xarr - min(xarr))\n",
    "probs /= max(probs)\n",
    "for x,y,p in zip(pos_x, pos_y, probs):\n",
    "    \n",
    "    # Set up the location; note we must invert y due to a pi rotation\n",
    "    #  about the x-axis.\n",
    "    r = Ellipse(xy=(x,y), width=2., height=2.);\n",
    "    r.set_facecolor('0');\n",
    "    r.set_alpha(0.02 + 0.98*p);\n",
    "    ax1.add_artist(r);\n",
    "ax1.set_xlabel(\"x (mm)\")\n",
    "ax1.set_ylabel(\"Y (mm)\")\n",
    "\n",
    "# Plot the grid.\n",
    "grid_vals = np.reshape(yarr,(-1,RNG_LIM))\n",
    "ax2 = fig.add_subplot(122)\n",
    "extent3 = [0, RNG_LIM, 0, RNG_LIM]\n",
    "sp3 = ax2.imshow(grid_vals, extent=extent3, interpolation='none', aspect='auto', origin='lower')\n",
    "ax2.set_xlabel(\"x (mm)\")\n",
    "ax2.set_ylabel(\"Y (mm)\")\n",
    "cbp3 = plt.colorbar(sp3);\n",
    "cbp3.set_label('Fractional Energy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set load_model to true and specify the file to load in a previously defined/trained model\n",
    "load_mdl = False\n",
    "mfile = 'models/slice_reconstruction.h5'\n",
    "\n",
    "if(load_mdl):\n",
    "    model = load_model(mfile)\n",
    "else:\n",
    "\n",
    "    # otherwise define the model\n",
    "    model = model_2dconv()\n",
    "    \n",
    "    # define callbacks (actions to be taken after each epoch of training)\n",
    "    file_lbl = \"{epoch:02d}-{loss:.4f}\"\n",
    "    filepath=\"weights-{0}.h5\".format(file_lbl)\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    tboard = callbacks.TensorBoard(log_dir='./logs', write_graph=True, write_images=False)\n",
    "    lcallbacks = [checkpoint, tboard]  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(x_train, y_train, epochs=10, batch_size=50, validation_data=(x_test,y_test), callbacks=lcallbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and produce a list of predictions for the test data.\n",
    "loss_and_metrics = model.evaluate(x_test, y_test);\n",
    "y_pred = model.predict(x_test, batch_size=32, verbose=0)\n",
    "print(\"\\nMean loss is {0}\".format(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true vs. reconstructed for a test event.\n",
    "pevt = np.random.randint(0,1999)\n",
    "pevt = 19\n",
    "xarr = x_test[pevt]\n",
    "y_true = y_test[pevt]\n",
    "y_calc = y_pred[pevt]\n",
    "\n",
    "# Create the figure.\n",
    "fig = plt.figure();\n",
    "fig.set_figheight(5.0)\n",
    "fig.set_figwidth(15.0)\n",
    "extent = [0, RNG_LIM, 0, RNG_LIM]\n",
    "\n",
    "# Plot the SiPM response map.\n",
    "ax1 = fig.add_subplot(121); \n",
    "ax1.axis([0, xlen, 0, ylen]);\n",
    "probs = (xarr - min(xarr))\n",
    "probs /= max(probs)\n",
    "for x,y,p in zip(pos_x, pos_y, probs):\n",
    "    \n",
    "    # Set up the location; note we must invert y due to a pi rotation\n",
    "    #  about the x-axis.\n",
    "    r = Ellipse(xy=(x,y), width=2., height=2.);\n",
    "    r.set_facecolor('0');\n",
    "    r.set_alpha(0.02 + 0.98*p);\n",
    "    ax1.add_artist(r);\n",
    "ax1.set_xlabel(\"x (mm)\")\n",
    "ax1.set_ylabel(\"Y (mm)\")\n",
    "\n",
    "# Plot the truth.\n",
    "ax1 = fig.add_subplot(121);\n",
    "grid_true = np.reshape(y_true,(-1,RNG_LIM))\n",
    "sp3 = ax1.imshow(grid_true, extent=extent, interpolation='none', aspect='auto', origin='lower')\n",
    "ax1.set_xlabel(\"x (mm)\")\n",
    "ax1.set_ylabel(\"Y (mm)\")\n",
    "ax1.set_title(\"True Energy Distribution\")\n",
    "cbp3 = plt.colorbar(sp3);\n",
    "cbp3.set_label('Fractional Energy');\n",
    "\n",
    "# Plot the grid.\n",
    "ax1 = fig.add_subplot(122); \n",
    "ax1.axis([0, xlen, 0, ylen]);\n",
    "probs = (xarr - min(xarr))\n",
    "probs /= max(probs)\n",
    "for x,y,p in zip(pos_x, pos_y, probs):\n",
    "    \n",
    "    # Set up the location; note we must invert y due to a pi rotation\n",
    "    #  about the x-axis.\n",
    "    r = Ellipse(xy=(x,y), width=2., height=2.);\n",
    "    r.set_facecolor('0');\n",
    "    r.set_alpha(0.02 + 0.98*p);\n",
    "    ax1.add_artist(r);\n",
    "ax1.set_xlabel(\"x (mm)\")\n",
    "ax1.set_ylabel(\"Y (mm)\")\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "grid_calc = np.reshape(y_calc,(-1,RNG_LIM))\n",
    "sp3 = ax2.imshow(grid_calc, extent=extent, interpolation='none', aspect='auto', origin='lower')\n",
    "ax2.set_xlabel(\"x (mm)\")\n",
    "ax2.set_ylabel(\"Y (mm)\")\n",
    "ax2.set_title(\"Reconstructed Energy Distribution\")\n",
    "cbp3 = plt.colorbar(sp3);\n",
    "cbp3.set_label('Fractional Energy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = plt.plot(range(0,len(hist.history['loss'])),\n",
    "                 np.array(hist.history['loss']), 'r', label='Train error')\n",
    "val   = plt.plot(range(0,len(hist.history['loss'])),\n",
    "                 np.array(hist.history['val_loss']), 'b', label='Val error')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Xentropy')\n",
    "plt.title('DNN Track Reconstruction Error')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
